
== Calculating Topographic Shielding

Cosmogenic nuclides are produced at or near the Earth's surface by cosmic rays,
and these rays can be blocked by topography (i.e., big mountains cast "shadows" for cosmic rays).

In most cases, you will not have topographic shielding rasters available, and will need to calculate these.

Shielding calculation are computationally intensive, much more so than the actual erosion rate computations.
Because of the computational expense of shielding calculations, we have prepared a series of tools for speeding this computation.

The topographic shielding routines take the rasters from the `_CRNRasters.csv` file and the `_CRNData.csv` file and computes the location of all CRN basins.
They then clips a DEM around the basins (with a pixel buffer set by the user).
These clipped basins are then used to make the shielding calculations and the erosion rate calculations.

This process of clipping out each basin spans a large number of new DEM that require a new directory structure.
A python script is provided to set up this directory structure in order to organize the new rasters.

WARNING: *This process uses a large amount of storage on the hard disk because a new DEM will be written for each CRN basin.*

=== Steps for preparing the rasters for shielding calculations

==== Creation of subfolders for your topographic datasets

The first step is to create some subfolders to store topographic data.
We do this using a python script

. First, place the `_CRNRasters.csv` and `_CRNData.csv` file into the same folder,
and make sure the `_CRNRasters.csv` file points to the directories that contain the topographic data.
If you are working with the example data (see section <<Getting example data: The San Bernardino Mountains>>),
you should navigate to the folder with the data (for this example, the folder is in `/home/ExampleDatasets/SanBernardino/`):
+
[source,console]
----
$ pwd
/home/ExampleDatasets/SanBernardino/
$ ls
SanBern_CRNData.csv  SanBern_CRNRasters.csv  SanBern.hdr
SanBern.bil         SanBern.CRNparam
----
+
You will then need to modify `SanBern_CRNRasters.csv` to reflect your directory:
+
.Modify your `SanBern_CRNRasters.csv` file
[source,paramfile]
----
/home/ExampleDatasets/SanBernardino/SanBern
----
+
Each line in this file points to a directory holding the rasters to be analyzed. 
+
In this case we are not supplying and shielding rasters.
For more details about the format of this file see the section: <<The raster names file>>.
+
. Second, run the python script `PrepareDirectoriesForBasinSpawn.py`.
+
* You can clone this script from GitHub; find it here: https://github.com/LSDtopotools/LSDAutomation
You will also need the file `LSDOSystemTools.py` from this repository.
The `LSDOSystemTools.py` file contains some scripts for making sure directories are in the correct format,
and for changing filenames if you happen to be switching between Linux and Windows.
It is unlikely that you will need to concern yourself with its contents, as long as
it is present in the same folder as the `PrepareDirectoriesForBasinSpawn.py` file.
+
The scripts can be downloaded directly using:
+
[source,console]
----
$ wget https://github.com/LSDtopotools/LSDAutomation/raw/master/PrepareDirectoriesForBasinSpawn.py
$ wget https://github.com/LSDtopotools/LSDAutomation/raw/master/LSDOSystemTools.py
----
+
* You will need to scroll to the bottom of the script and change the `path`
(which is simply the directory path of the `_CRNRasters.csv` file.
* You will need to scroll to the bottom of the script and change the `prefix`
(which is simply prefix of the ``_CRNRasters.csv`` file; that is the filename before `_CRNRasters.csv`
so if the filename is `YoYoMa_CRNRasters.csv` then `prefix` is `YoYoMa`. Note this is case sensitive.
+
In this example, scroll to the bottom of the file and change it to:
+
[source,python]
----
if __name__ == "__main__":
    path = "/home/ExampleDatasets/SanBernardino"
    prefix = "SanBern"
    PrepareDirectoriesForBasinSpawn(path,prefix)
----
+
* This python script does several subtle things like checking directory paths and then makes a new folder for each DEM.
The folders will contain all the CRN basins located on the source DEM.
+
If you are using the example data, the rather trivial result will be a directory called `SanBern`.

==== Spawning the basins

Now you will run a pass:[C++] program that spawns small rasters that will be used for shielding calculations.
First you have to compile this program.


. To compile, navigate to the folder `/home/LSDTT_repositories/LSDTopoTools_CRNBasinwide/driver_functions_CRNBasinwide/`.
If you put the code somewhere else, navigate to that folder.
Once you are in the folder with the driver functions, type:
+
[source,console]
----
$ make -f Spawn_DEMs_for_CRN.make
----
+
. The program will then compile (you may get some warnings--ignore them.)

. In the `/driver_functions_CRNTools/` folder, you will now have a program `Spawn_DEMs_for_CRN.exe`.
You need to give this program two arguments.

. You need to give `Spawn_DEMs_for_CRN.exe`, the path to the data files (i.e., `_CRNRasters.csv` and `_CRNData.csv`),
and the prefix, so if they are called  `YoMa_CRNRaster.csv` the prefix is `YoMa`). In this example the prefix will be `SanBern`. 
Run this with:
+
[source,console]
----
PS> Spawn_DEMs_for_CRN.exe PATHNAME DATAPREFIX
----
+
in windows or:
+
[source,console]
----
$ ./Spawn_DEMs_for_CRN.exe PATHNAME DATAPREFIX
----
+
in Linux.
+
In our example, you should run:
+
[source,console]
----
$ ./Spawn_DEMs_for_CRN.exe /home/ExampleDatasets/SanBernardino/ SanBern
----
+
WARNING: The PATHNAME **MUST** have a frontslash at the end.
`/home/ExampleDatasets/SanBernardino/` will work whereas `/home/ExampleDatasets/SanBernardino` will lead to an error.
+
. Once this program has run, you should have subfolders containing small DEMs that contain the basins to be analyzed.
There will be one for every cosmogenic sample that lies within the DEM.
+
. You will also have files that contain the same `PATHNAME` and `PREFIX` but have `_Spawned` added to the prefix.
For example, if your original prefix was  `CRN_test`, the new prefix will be `CRN_test_Spawned`.
+
. In the file `PREFIX_Spawned_CRNRasters.csv` you will find the paths and prefixes of all the spawned basins.

=== The shielding computation

The shielding computation is the most computationally expensive step of the CRN data analysis.
Once you have spawned the basins (see above section,
<<Steps for preparing the rasters for shielding calculations>>), you will need to run the shielding calculations.

. You will first need to compile the program that calculates shielding. This can be compiled with:
+
[source,console]
----
$ make -f Shielding_for_CRN.make
----
+
. The compiled program (`Shielding_for_CRN.exe`) takes two arguments: the `PATHNAME` and the `PREFIX`.

. You could simply run this on a single CPU after spawning the basins;
for example if the original data had the prefix `CRN_test` before spawning, you could run the program with:
+
[source,console]
----
$ ./Shielding_for_CRN.exe PATHNAME CRN_test_Spawned
----
+
where `PATHNAME` is the path to your `_CRNRasters.csv`, `_CRNData.csv`, and `.CRNParam` (*these files need to be in the same path*).
+
NOTE: If you only wanted to do a subset of the basins, you can just delete rows from the `*_Spawned_CRNRasters.csv` file as needed.

This will produce a large number of topographic shielding rasters (with `_SH` in the filename), for example:

.A partial list of files generated by spawning operation
[source,console]
----
smudd@burn SanBern $ ls
SpawnedBasin_10.bil  SpawnedBasin_17.bil  SpawnedBasin_7.bil       SpawnedBasin_MHC-13.bil
SpawnedBasin_10.hdr  SpawnedBasin_17.hdr  SpawnedBasin_7.hdr       SpawnedBasin_MHC-13.hdr
SpawnedBasin_11.bil  SpawnedBasin_18.bil  SpawnedBasin_8.bil       SpawnedBasin_MHC-14.bil
SpawnedBasin_11.hdr  SpawnedBasin_18.hdr  SpawnedBasin_8.hdr       SpawnedBasin_MHC-14.hdr
SpawnedBasin_12.bil  SpawnedBasin_19.bil  SpawnedBasin_9.bil       SpawnedBasin_MHC-15.bil
SpawnedBasin_12.hdr  SpawnedBasin_19.hdr  SpawnedBasin_9.hdr       SpawnedBasin_MHC-15.hdr
----

.One of the shielding rasters (for sample name `18`) from the San Bernardino dataset (viewed in QGIS2.2)
image::images/Shielding.jpg[Shielding raster]

=== Embarrassingly parallel shielding

We provide a python script for running multiple basins using an https://en.wikipedia.org/wiki/Embarrassingly_parallel[embarrassingly parallel] approach.
It is written for our cluster:
if your cluster uses `qsub` or equivalent, you will need to write your own script.
However, this will work on systems where you can send jobs directly.

. To set the system up for embarrassingly parallel runs, you need to run the python script `ManageShieldingComputation.py`,
which can be found here: https://github.com/LSDtopotools/LSDAutomation.
You can download it with:
+
[source,console]
----
$ wget https://github.com/LSDtopotools/LSDAutomation/raw/master/ManageShieldingComputation.py
----
+
. In `ManageShieldingComputation.py`, navigate to the bottom of the script, and enter the `path`, `prefix`, and `NJobs`.
`NJobs` is the number of jobs into which you want to break up the shielding computation.
+
. Once you run this computation, you will get files with the extension `_bkNN` where `NN` is a job number.
+
. In addition a text file is generated, with the extension `_ShieldCommandPrompt.txt`,
and from this you can copy and paste job commands into a Linux terminal.
+
WARNING: **These commands are designed for the GeoSciences cluster at the University of Edinburgh:
if you use `qsub` you will need to write your own script**.
+
. Note that the parameters for the shielding calculation are in the `.CRNParam` files. We recommend:
+
[source,paramfile]
----
theta_step:8
phi_step: 5
----
+
These are based on extensive sensitivity analyses and balance computational speed with accuracy.
Errors will be << 1% even in landscapes with extremely high relief. Our forthcoming paper has details on this.
+
. Again, these computations take a long time. *Don't start them a few days before your conference presentation!!*

. Once the computations are finished, there will be a shielding raster for every spawned basin raster.
In addition, the `_CRNRasters.csv` file will be updated to reflect the new
shielding rasters so that the updated parameter files can be fed directly into the erosion rate calculators.

=== Once you have finished with spawning and topographic shielding calculations

If you are not going to assimilate reported snow shielding values, you can move on to the erosion rate calculations. 
If you are going to assimilate reported snow shielding values, please read the section: <<Using previously reported snow shielding>>.

=== Stand alone topographic shielding calculations

We also provide a stand alone program just to calculate topographic shielding. This may be useful for samples collected for
measuring exposure ages or for working in other settings such as active coastlines. 

. You will first need to compile the program that calculates topographic shielding. This can be compiled with:
+
[source,console]
----
$ make -f TopoShielding.make
----
+
. The compiled program (`TopoShielding.out`) takes four arguments: the `PATHNAME`, the `PREFIX`, the `AZIMUTH STEP` and the `ANGLE STEP`.

. You could simply run this on a single CPU;
for example if the original DEM had the prefix `CRN_TEST` before spawning, and you wanted to use an `AZIMUTH_STEP=5` and `ANGLE_STEP=5`,
you could run the program with:
+
[source,console]
----
$ ./TopoShielding.out PATHNAME CRN_TEST 5 5
----
+
where `PATHNAME` is the path to your `CRN_TEST`.
+
NOTE: The DEM must be in ENVI *.bil format. See link:LSDTT_introduction_to_geospatial_data.html#_what_data_does_lsdtopotools_take[information about LSDTopoTools data formats].

This will produce a single topographic shielding raster (with `_TopoShield` in the filename).

== Snow shielding calculations

Snow absorbs cosmic rays and so CRN concentrations in sediments can be affected 
by snow that has been present in the basin during the period that eroded materials were exposed to cosmic rays. 

Estimating snow shielding is notoriously difficult 
(how is one to rigorously determine the thickness of snow averaged over the last few thousand years?),
and our software does not prescribe a method for calculating snow shielding. 

Rather, our tools allow the user to set snow shielding in 3 ways:

. Use a previously reported basinwide average snow shielding factor
. Assign a single effective average depth of snow over a catchment (in g cm^-2^).
. Pass a raster of effective average depth of snow over a catchment (in g cm^-2^).

=== Using previously reported snow shielding

Some authors report a snow shielding factor in their publications. 
The underlying information about snow and ice thickness used to generate the snow shielding factor is usually missing. 
Because under typical circumstances the spatial distribution of snow thicknesses is not reported, we use reported snow shielding factors
to calculate an effective snow thickness across the basin. 

This approach is only compatible with our spawning method (see the section on <<Spawning the basins>>), 
because this average snow thickness will only apply to the raster containing an individual sample's basin. 

The effective snow thickness is calculated by:

.Converting snow shielding to an effective depth
[latexmath]
++++
d_{eff} = -\Gamma_0*\ln(S_s)
++++

where stem:[d_{eff}] is the effective depth (g cm^-2^), stem:[\Gamma_0] is the attenuation mass (= 160 g cm^-2^) for spallation (we do not consider the blocking of muons by snow), and, stem:[S_s] is the reported snow shielding. 

The reported snow shielding values should be inserted as the 8th column in the `CRNData.csv` file.

For example, 

.A CRNData.csv file with shielding (Note this is not actual data! The snow shielding values are random).
[source,paramfile]
----
Sample_name,Latitude,Longitude,Nuclide,Concentration,Uncertainty,Standardisation,Snow_shield
20,34.3758,-117.09,Be10,215100,9400,07KNSTD,0.661531836
15,34.3967,-117.076,Be10,110600,7200,07KNSTD,0.027374149
19,34.4027,-117.063,Be10,84200,6500,07KNSTD,0.592583113
17,34.2842,-117.056,Be10,127700,5800,07KNSTD,0.158279369
14,34.394,-117.054,Be10,101100,6100,07KNSTD,0.047741051
18,34.2794,-117.044,Be10,180600,10000,07KNSTD,0.559339639
11,34.1703,-117.044,Be10,7700,1300,07KNSTD,0.210018127
16,34.2768,-117.032,Be10,97300,5500,07KNSTD,0.317260607
10,34.2121,-117.015,Be10,74400,5200,07KNSTD,0.253863843
----

==== Steps to use reported snow shielding

Reported snow shielding values are done on a basin-by-basin basis, so our snow shielding must have individual shielding calculations for each sample. 
This is only possible using our "spawning" routines. 

. The spawning of basins must be performed: see <<Spawning the basins>>
. The `*_spawned_CRNData.csv` should have snow shielding values in the 8th column. 
. A python script, `JoinSnowShielding.py`, must be run that translates reported snow shielding values into effective depths. 
This script, and a required helper script, `LSDOSystemTools.py`  can be downloaded from:
+
[source,console]
----
$ wget https://github.com/LSDtopotools/LSDAutomation/raw/master/JoinSnowShielding.py
$ wget https://github.com/LSDtopotools/LSDAutomation/raw/master/LSDOSystemTools.py
----
+
You will need to scroll to the bottom of the `JoinSnowShielding.py` program and edit both the path name and the file prefix. 
For example, if your spawned data was in `/home/ExampleDatasets/SanBernardino/` and the files were `SanBern_spawned_CRNRasters.csv`, `SanBern_spawned_CRNData.csv`, and `SanBern_spawned.CRNParam`, then the bottom of the python file should contain:
+
[source,python]
----
if __name__ == "__main__":
    path = "/home/ExampleDatasets/SanBernardino"
    prefix = "SanBern_spawned"
    GetSnowShieldingFromRaster(path,prefix)  
----
+
. This script will then modify the `*spawned_CRNRasters.csv` so that the second column will have an effective snow shiedling reflecting the reported snow shielding value 
(converted using the equation earlier in this section). It will print a new file, `*spawned_SS_CRNRasters.csv` and copy the CRNData and CRNParam files to ones with prefixes:
`*_spawned_SS_CRNData.csv` and `*_spawned_SS.CRNParam`.
+
. These new files (with `_SS` in the prefix) will then be used by the erosion rate calculator. 

=== Assign a single effective average depth

This option assumes that there is a uniform layer of time-averaged snow thickness over the entire basin. 
The thickness reported is in effective depth (g cm^-2^). 

To assign a constant thickness, one simply must set the section column of `*_CRNRasters.csv` file to the appropriate effective depth.

For example, a file might look like:

.An example CRNRasters.csv file with constant snow shielding
[source,paramfile]
----
/home/topodata/SanBern,15
/home/topodata/Sierra,15,0
/home/topodata/Ganga,15,0,/home/topodata/Ganga_shielded
----

In the above example the first row just sets a constant effective depth of 15  g cm^-2^, 
The second also assigns a self shielding value of 0 g cm^-2^ (which happens to be the default), 
and the third row additionally identifies a topographic shielding raster. 

In general, assigning a constant snow thickness over the entire DEM is not particularly realistic, 
and it is mainly used to approximate the snow shielding reported by other authors when they have not made the spatially distributed data about snow thicknesses available
see <<Using previously reported snow shielding>>.  

=== Pass a raster of effective average depth of snow over a catchment

Our software also allows users to pass a raster of effective snow thicknesses (g cm^-2^). 
This is the time-averaged effective thickness of snow which can be spatially heterogeneous.

The raster is given in the second column of the `*_CRNRasters.csv`, so, for example in the below file the 4th and 6th rows point to snow shielding rasters. 

.An example CRNRasters.csv file
[source,paramfile]
----
/home//basin_data/Site01/Site01_DEM,0,0,/home/basin_data/Site01/Site01_DEM_TopoShield
/home/basin_data/Site02/Site02_DEM,5,10
/home/basin_data/Site03/Site03_DEM,5,/home/basin_data/Site03/Site03_DEM_SelfShield
/home/basin_data/Site04/Site04_DEM,/home/basin_data/Site04/Site04_DEM_SnowShield,/home/basin_data/Site04/Site04_DEM_SelfShield
/home/basin_data/Site05/Site05_DEM
/home/basin_data/Site06/Site06_DEM,/home/basin_data/Site06/Site06_DEM_SnowShield
----

IMPORTANT: The snow shielding raster must be the same size and shape as the underlying DEM 
(i.e. they must have the same number of rows and columns, same coordinate system and same data resolution).

IMPORTANT: These rasters need to be assigned *BEFORE* spawning since the spawning process will clip the snow rasters to be the same size as the clipped topography for each basin. 

=== Compute snow shielding from snow water equivalent data

In some cases you might have to generate the snow shielding raster yourself. We have prepared some python scripts and some pass:[C++] programs that allow you to do this.

1. First, you need to gather some data. You can get the data from http://www.wcc.nrcs.usda.gov/snow/snotel-wedata.html[snow observations], or from https://nsidc.org/data/nsidc-0271[reconstructions]. The simple functions we have prepared simply approximate snow water equivalent (SWE) as a function of elevation. 
+
2. You need to take your study area, and prepare a file that has two columns, seperated by a space. 
The first column is the elevation in metres, and the second column is the average annual snow water equivalent in mm. 
Here is an example from Idaho:
+
[source,paramfile]
----
968.96	70.58333333
1211.2	16
1480.692	51.25
1683.568	165.8333333
1695.68	115.4166667
1710.82	154.1666667
1877.36	139.75
1925.808	195.1666667
1974.256	277.75
2240.72	253.0833333
2404.232	241.5833333
2395.148	163.0833333
----
+
3. Once you have this file, download the following python script from our repository:
+
[source,console]
----
$ wget https://github.com/LSDtopotools/LSDTopoTools_CRNBasinwide/raw/master/SnowShieldFit.py
----
+
4. Open the python file and change the filenames to reflect the name of your data file withing the python script, here (scroll to the bottom):
+
[source,python]
----
if __name__ == "__main__":

    # Change these names to create the parameter file.  The first line is the name
    # of the data file and the second is the name of the parameter file
    filename = 'T:\\analysis_for_papers\\Manny_idaho\\SWE_idaho.txt'
    sparamname = 'T:\\analysis_for_papers\\Manny_idaho\\HarringCreek.sparam'
----
+
This script will fit the data to a bilinear function, shown to approximate the SWE distribution with elevation in a number of sites. You can read about the bilinear fit in a paper by http://www.hydrol-earth-syst-sci.net/18/4261/2014/hess-18-4261-2014.html[Kirchner et al., HESS, 2014] and by 
http://www.the-cryosphere.net/8/2381/2014/[Gr√ºnewald et al., Cryosphere, 2014].
+ 
For reasons we will see below the prefix (that is the pit before the `.sparam`) should be the same as the name of the elevation DEM upon which the SWE data will be based.
+
5. Run the script with:
+
[source,console]
----
$ python SnowShieldFit.py
----
+
6. This will produce a file with the extension sparam. The .sparam file contains the slope and intercept for the annual average SWE for the two linear segments, but in units of g cm^-2^.
These units are to ensure the snow water equivalent raster is in units compatible with effective depths for cosmogenic shielding. 
+
IMPORTANT: The data file you feed in to `SnowShieldFit.py` should have SWE in mm, whereas the snow shielding raster will have SWE in effective depths with units g cm^-2^.
+
7. Okay, we can now use some pass:[C++] code to generate the snow shielding raster. If you cloned the repository (using `git clone https://github.com/LSDtopotools/LSDTopoTools_AnalysisDriver.git`), you will have a function for creating a snow shielding raster. Navigate to the `driver_functions` folder and make the program using:
+
[source,console]
----
$ make -f SimpleSnowShield.make
----
+
8. You run this program with two arguments. The first argument is the path to the `.sparam` file that was generated by the script `SnowShieldFit.py`. The path **MUST** include a final slash (i.e. `/home/a/directory/` will work but `/home/a/directory` will fail.)
The second argument is the prefix of the elevation DEM **AND** the `.sparam` file (i.e. if the file is `HarringCreek.sparam` then the prefix is `HarringCreek`). The code will then print out an `bil` format raster with the prefix plus `_SnowBL` so for example if the prefix is `HarringCreek` then the output raster is `HarringCreek_SnowBL.bil`. The command line would look something like:
+
[source,console]
----
$ ./
----
+
IMPORTANT: The prefix of the `.sparam` file **MUST** be the same as the DEM prefix. 
+
9. Congratulations! You should now have a snow shielding raster that you can use in your CRN-based denudation rate calculations. 
NOTE: The program `SimpleSnowShield.exe` can also produce SWE rasters using a modified Richard's equation, which has been proposed by
http://onlinelibrary.wiley.com/doi/10.1002/2015GL063413/epdf[Tennent et al., GRL], but at the moment we do not have functions that fit
SWE data to a Richard's equation so this is only recommended for users with pre-calculated parameters for such equations. 
10. If you have performed this step after spawning the DEMs (see the section <<Spawning the basins>>), you can update the `_CRNRasters.csv` by running the python script `PrepareCRNRastersFileFromDirectory.py`, which you can read about in the section: <<Modifying your CRNRasters file the python way>>.  




