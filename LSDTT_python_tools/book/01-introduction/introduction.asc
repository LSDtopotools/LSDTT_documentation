:numbered:

== Forewords

This guide aims to explain our `Python` bindings for `LSDTopoTools` algorithms (as many as possible). In this guide, we will go through:

- the reasons of developping such a tool; how to quickly install and use it on `Windows`, `linux` (and probably `Mac`)
- how the code works and how to run the different routines
- our set of automated plotting routines and how to build yours
- and finally a development guide for the lower-level interfaces

WARNING: These tools are still in early development and might be quite unstable.

== Introduction

LSDTopoTools is an open-source research software proving a large set of algorithms to quantitatively describe the morphology of landscapes. It covers a wide range of geomorphological applications with preprocessing routines (e.g., depression filling or carving, filtering), flow routines (Flow direction, accumulation, node ordering, ...), channel network extraction and advanced channel head location (TODO::references), blabla TODO::List application with references when my Mendeley will work again. +
The core of he code is written in `cpp`, a fast and compiled low level language. Its main advantages is its speed, its flexibility (fine grained management of `memory` and `cpu`) and its wide community. Our algorithms are widely tested and developped in `cpp` and direct access is available through source code and docker containers (TODO:: ink to other doc pages). +

=== Why a Python Version

`python` has many advantages:

- *Free* and *open-source*, making it a research-friendly language, as research should be accessible to anyone without the need of expensive proprietary software (not all universities, research institutes or individuals have access to MATLAB, ArcGIS or ERDAS for example).

- it is popular and has a *HUGE* community ready to help if you have a question.

- it is easy-to-read and has several level of difficulties: it can only be used as a scripting language (= just telling few instruction to the computer, basically as easy as talking to a child) if needed.

- it is packaged-based: you can install bit of codes other people made really easily and use it. No need to reinvent the wheel if it is already fast enough.

- Finally, it is simple to install and universal: you can use it on Windows, Linux, Mac, ... ++

These are the reasons for developping a `python` binding for our tools.

Of course python also has some drawbacks. It simplicity comes with a cost of performances:

- Large numerical operations in pure `python` can quickly become slow and you need to find the package that has been optimising the specific routine you want and has binded it to `python`. This is the case for most of the "common" routines (e.g., see `scipy` and `numpy` for an impressive collection of fast and fully coded numerical routines), but everything is not coded yet.

- `Python` can become a bit confusing as there are many different ways and packages to do a tasks. +

+
These are the reasons we are still coding in `cpp` and providing access to these fast and optimised routines from `python`: our solution therefore combine the simplicity, portability and software-catalog of `python` with the raw powerfullness of `cpp`. The only remaining drawback is that it requires some gymnastics behind the scene to transfer data between the two and to make easy installer, but you won't care about that because we are doing it for you.

=== How

Some wonderful tools have make this binding possible and deserve credits:
- `xtensors`, a `cpp` data structure with (_inter alia_) in-built linkage with the universally used `python numpy ndarrays`. This is developped by http://quantstack.net/[Quantstack], I recommend having a look on the tools they develop for research, they are truly amazing

- `pybind11`, a complete toolbox to bind `cpp` data structure to `python` objects. This low-level interface, `lsdtt_xtensor_python`, is the backbone of the bindings: it communicates directly with `cpp` and deal with internal memory ownership and this kind of questions. +

Using these tools, we provide two packages to use our code from `python`:

- `lsdtt_xtensor_python`, a low level interface. You may be interested by using directly this backend only if you want python access to the `cpp` code with minimum dependencies: if already built in `pip`, it only requires `pybinds` and `numpy` to run but requires minimum knowledge on `LSDTopoTools` code structure.

- `lsdtopytools`, built on the top of `lsdtt_xtensor_python`, it provides a user friendly interface to the code with straighforward functions and lot of automations. It also provides additional routine to loads most of the raster types (e.g., `tif`, `bil`, `ASCII grids`), easy I/O operations, visualisations, and can easily be linked with any other packages.
// . A command line interface (Soon.)

== Installation

Soon, a `conda` receipe will be available, making the installation extremely straigh forward. But before that, it still requires few simple manipulations as I am still working on the best way to do it.

.If you know how python works
*********************************************
Quick instruction if you are used to python environments: +
*lsdtt_xtensor_python (required for any use)* +
So far there are two cases: either we have already built binaries for your OS/cpu: +
`pip install lsdtt_xtensor` will be extremely fast and easy, we have wheels for windows for sure at the moment (linux is somehow tricky, and I don't have a mac). +
Otherwise you have to build it on your own machine (soon to be sorted with the conda reicepe): +
`conda install -c conda-forge pybind11 xtensor xtensor_python numpy` +
Then you need a `cpp14` ready default compiler (again, this is temporary). If you reach this stage, you are probably on linux so install a gcc>=5 and you shall be alright. `pip install lsdtt_xtensor` will now take a while but will work (it is directly compiling the code on your machine). +
*lsdtopytools and command-line (for the simple interface)* +
Relatively easy: Install the dependencies and then the package. +
`conda install -c conda-forge numpy scipy pandas numba matplotlib gdal rasterio h5py` +
`pip install lsdtopytools`
*********************************************

The following guide gives you a step-by-step installation guide. It assumes no particular knowledge in computers/coding and will point to external tutorials when potentially needed. It will also explain the different steps, you don't have to read it if you are in a hurry, but te more you understand what is happenning in the computer, the easier it is to debug it (and indirectly, less complaining emails for us as well).

=== A python environment

If you already are confortable with `python` and already have your own environment, you can skip that part.

==== What is a python environment and why

The first step is to create a python environment. As stated before, `python` is a "_packaged_" language: all the code take advantage of other bit of codes made by the community called packages. The (really) good thing with it is that a lot of algorithms are already coded and you can integrate it in your `python` environment easily. +
The backside is that many packages relies on specific version of other packages and there can be some conflict when the environment becomes massif, the same way ArcGIS extentions are only compatible with some version of this software, or MATLAB scripts that absolutely require the specific version `2015rc4267-21f-march2016v2.5` to run. +
On the bright side, `python` is free and open-source, you can therefore install as many versions of python and its packges as you want. We strongly advice to use `miniconda` as environment manager: you can create and activate different environments with their own packages. Even better, we can provide templates of environments to make it easy-to-install. +
A practical example: you can have one environment with `lsdtopytools` installed to run topographic analysis, a separate one with `landlab` to deals with modelling or even play with the packages to mix both tools in the same environment and run it together.

==== Installing ana/miniconda

You can download `miniconda` from https://conda.io/miniconda.html[this website], and install it. It does not matter whether you have `miniconda` or `anaconda`: these are just _light_ and *full* versions of the same tool. We advice `miniconda` to only install what you need and we advice `python 3.6` or `3.7`: we only tested our code on these versions. The code is theoretically compatible with `3.5`, `3.4` and `2.7` but I would imagine that if you need such a specific version of `python`, you'll know how to deal with custum installation. Also, you need to know if your computer is 32 (if old) or 64 bits (most of post 2010 computer). +
You do not need admin right to install `conda` on your machine in case you are using institutions servers or computers.

==== Terminal, cmd or conda prompt

As many (scientific) tools, the scripts need to be ran in a console/terminal/command prompt/whichever name you want. Many reasons for that: easier to manage, control and automate; quicker; actually easy to use. The only bad side is that it looks less attractive than a nice graphic interface. Basically, rather than double clic on a folder, you need to write `cd name_of_the_folder` to chagne the current directory for instance.

===== On Windows

After installing conda on `windows`, you can open a `conda prompt` from your start menu. Then you will be sure to be inside your `conda` environment and ready to navigate through your file tree to run programs. Here is a https://www.youtube.com/watch?v=MNwErTxfkUA[random tutorial] found online to learn to basics. There are many, you don't need advanced knowledge, basically jsut how to navigate through folders, list the files in the folder and stuff like that.

===== On linux

Depending on your `python` uses, you can either (i) add it to your `PATH` and make it your default `python` environment (it can make other program using default python unhappy, it is rare but it can happen); (ii) Follow https://conda.io/docs/user-guide/install/index.html#installing-conda-on-a-system-that-has-other-python-installations-or-packages[these instructions]. I assume you know how to deal with a terminal if you are using linux.

===== On Mac

Who knows, it should be similar to `linux` anyway.


==== Creating environment

You are now within a `conda` environment that includes `python`. Let's have a clean install, cleaner computing is easier to debug. The following command creates an ("sub")environment in you conda installation, where we will install the packages we need. To run the command, just copy-paste it in the terminal and hit `enter`. +

[source,terminal]
----
conda create -n lsdtt
----

Once created, the environment just need to be activate each time a new terminal is opened! You just have to run the following command:

[source,terminal]
----
conda activate lsdtt
----

You'll know it is activated if `(lsdtt)` is displayed in your terminal. If you have an old version of conda, you may face a message error. You just have to use this command instead:
[source,terminal]
----
source activate lsdtt
----

We're basically done with environment stuff. You can create as many (or as few) environment as you need for your different programs (_e.g., landlab, opencv_).

==== Installing the packages (Soon to be automated):

let's now install the required tools to run `lsdtt_xtensor_python` (the `cpp-python` mediator): we take advantage of carefully selected bits of other codes to help us. +
The following command installs package. `install` means (surprise) install, and `-c conda-forge` means from the channel (= repository) "conda-forge" which is in plain language a big pile of easy-to-install python packages. + The following keywords are the name of the packages: (i) `pip`, it makes easier `python` packages installation, (ii) `numpy`, an *EXTREMELY* used and powerful tools for arrays and matrix calculations. It is written in `fortran` and `c`, therefore its built-in functions (e.g., sum, median, reordering, and millions of common tools) are fast. (iii) `pybinds`, requires to link `cpp` to `python`. +

[source,terminal]
----
conda install -c conda-forge pip numpy pybinds
----

You environment is ready for `lsdtt_xtensor_python`:

[source,terminal]
----
pip install lsdtt_xtensor_python
----

WARNING: This was the trickest part, if the terminal throw a lot of error messages, it means that I did not manage yet to precompile the code for your platform. I am working on it but so far you need to build the package by yourself: it should be temporary. On linux: you need to install a recent compiler `gcc/gXX>=5` or any recent `clang` and to make sure it is your default compiler. Then you jsut need to install two other dependencies: `conda install -c conda-forge xtensor xtensor-python` and if you rerun the above `pip` command it will run for approximatively 10 minutes and install the package. On Windows: compiling on windows is fxxxxxg pain, I fought long long (long) hours to generate a wheel (compiled python package) theoretically compatible with any 64bits windows to avoid this issue, contact me if my wheel failed for you. On Mac: see linux.


`lsdtt_xtensor_python` is required for any use of the python tools, but only provide minimal interface with the `cpp` code and require knowledge of its structure. You probably now need `lsdtopytools`, the full, user-friendly interface that also provide (will provide actually as it is work in progress) easy raster loading/saving, ergonomic data management and visualisation routines. This however requires a bunch of other packages to be install: the simplest a program is, the bigger the amount of code behind is. +
`lsdtopytools`, even if you won't inteact with most of these, basically requires the following packages:

- `gdal`: a package, mostly in `C` that can deals with all the geodesy: projection, transformation, raster downsampling, WGS to UTM and billions of other tasks you don't want to face manually. https://lsdtopotools.github.io/LSDTT_documentation/LSDTT_introduction_to_geospatial_data.html#_gdal[More Information].

- `rasterio`: provides a nice interface to `gdal`, because I also want to simplify my coding when possible. https://rasterio.readthedocs.io/en/latest/[More Information].

- `scipy`: alongside with `numpy`, it provides quick and useful stats, filters, modelling, math, _etc_ routines for pre/post-processing. https://www.scipy.org/[More Information].

- `pandas`: provides table-like data analysis tools. Very useful to manage dataframes of thousands/millions of river points for examples. https://www.scipy.org/[More Information].

- `matplotlib`: paper-quality plots, unbeatable in this domains even if a bit frustrating sometimes. https://matplotlib.org/gallery/index.html[More Information].

- `numba`: I will get rid of that dependency at some point, it provides speed-up on some internal part of older code I used. Not really needed now I can send stuff to `cpp` directly with `numpy`, but I'll need time to recode these few routines, sns. http://numba.pydata.org/[More information].

- `h5py`: is (will be, may be, idk yet) used to save file to the disk: fast and well structured, it is theoretically a better alternative to `csv` files. Outputs with `csv` will still be available to link with Arc/QGIS if needed. https://www.h5py.org/[More Information].

+
To install, simply run:

[source,terminal]
----
conda install -c conda-forge gdal rasterio scipy pandas matplotlib numba h5py
----

It shall run for few minuts to install these dependencies, and finally you are ready for the last bit:
[source,terminal]
----
pip install lsdtopytools
----

This one should be universal (_i.e.,_ Compatible with with any OS as pure python stuffs).

And we are done with the installation!

==== Troubleshoot

There will be some, no worries.


