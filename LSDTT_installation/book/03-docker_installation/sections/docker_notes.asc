=== Some notes on Docker

The direction of travel in portability seems to be away from https://www.vagrantup.com/[Vagrant] and toward https://www.docker.com/[Docker]. We are not quite sure why this is, since the https://docs.docker.com/[docker documentation] is similar to documentation for the https://www.youtube.com/watch?v=rLDgQg6bq7o[turbo encabulator]. There are many people quite willing to mansplain why Docker is better but before you feel the urge to do that, please refrain: we have drank a bit of the kool-aid and have been testing *LSDTopoTools* with docker. 

==== Docker on Linux

After you install docker on Linux, you will need to add users to the docker permissions:

[source,console]
----
$ sudo usermod -a -G docker $USER
----

Once you have done this you will need to log out and log back in again. 


==== Docker for Windows

I have not made any scientific study of this but most *LSDTopoTools* users are on Windows operating systems. 

Firstly, you need to have *Windows 10 Enterprise*. It will not work otherwise. If you don't have Windows 10 Enterprise but are on Windows you probably should use the Vagrant instructions. If you do have Windows 10 enterprise then you can download and install Docker for Windows CE. After you install this you will need to restart your computer not once but twice: once after intall and a second time to activate the hyper-V feature, which allows you to have 64 bit guest operating systems.

Second, if you have that and have it installed, you also need to add yourself to the `docker-users` group. To do that, do this (instructions from here: https://github.com/docker/for-win/issues/868):

. Logon to Windows as Administrator
. Go to Windows Administrator Tools
. Look for Windows Computer Management and click on it.
. Or you can skip steps 1, right mouse clicking Computer Management, go to more, and select run as administrator and provide Administrator password.
. Double click docker-users group and add your account as member.
. Also add your account to Hyper-V Administrator. This was added when you installed docker for Windows.
. Log off from Windows and log back on.
. Click on Windows icon on bottom left and start Docker for Windows. This will start docker windows service.
. Start Windows Powershell and type docker --version. It will show Docker version 17.09.1-ce, build 19e2cf6. This is the latest version.

==== Building a base image

By the time these notes go online, there should be a functioning docker image that you can download from the docker hub.
The instructions will be clear and users can just start running *LSDTopoTools* from within docker.
These notes exists as something of a history or cheat sheet of how we made the base image. 

Before we do anything, you should look at some notes about running a functioning image of ubuntu: 
http://phusion.github.io/baseimage-docker/ 

I have no idea if that stuff is important! 
But we will try to test images that both include and don't incude a fully formed startup environment. 

The other big issue with docker is the volume syncing. This is more difficult to understand syncing in vagrant. 

===== A simple docker image

So basically for *LSDTopoTools* functionality we might want a few different base images:

* An image just for the pass:[c++] code.
* An image just for the python scripts.
* An image just for building documentation.
* An image with everything installed.

The reason why we might separate the first three images is because the python image will be *HUGE* whereas the *LSDTopoTools* source code is small. 
So people might want to be offered a slimm version. 

Lets start with a very simple python image. 
The docker documentation for getting you started up is not so useful because they are written to get you running an app in the docker box. For our purposes we want:

. To log into to the docker container via ssh or access it as though you have a little linux box running
. To be able to access you file system (we don't want to be having to ftp files in an out of the container each time or worse yet losing all our work when the docker session ends). 

For python, we could go with a full python build but that results in very large containers (over a GB). 
We will https://blog.realkinetic.com/building-minimal-docker-containers-for-python-applications-37d0272c52f3[follow advice for a minimal python installation]. For this we will use the https://hub.docker.com/_/alpine/[Alpine base box].

. First, create a directory that will contain the files you need. I'll call it `python_test`.
. Go into this directory. You will keep something called a `dockerfile` in this directory. 
It has instructions for what stuff is included in the container. 
We will start with an incredibly simple one. Create the follwoing textfile, called `dockerfile`:
+
[source,dockerfile]
----
FROM python:3.6-alpine

COPY . /app
WORKDIR /app
----
+
. Before we do anything we need to `build` the container. You build it with some name, like:
+
[source,console]
----
$ docker build -t chumbucket .
----
+ 
In this command, the `-t` tells docker to tag the container, the `chumbucket` gives the container its tag, and the `.` means that you want to call the `Dockerfile` from this directory. 
+
. This downloads some stuff and then hopefully tells you the container is sucessfully built. You can look at it with `docker image ls`.
+
. You need to actually run the image if you want to do anything with it:
+
[source,console]
----
$ docker run -it chumbucket sh
----
+
. The `-it` means `interactive` and `tag` and you give it the tag. You then tell it to run the shell (`sh`). To get out of the shell simply type `ctrl-d`.
+
. This gets you into a python container, and in addition it has a (very old version of) pip installed. It breaks if you try to install even simple things like pandas. This makes it totally unusable so we are going to have to add some stuff to the docker file. Unfortunately the alpine distro has all sorts of fundamental problems, for example you can't install scipy.  




===== A slightly more complicated python image

Okay, that container only has a very simple version of python on it. You can then install https://pypi.org/project/pip/[pip] and try to get some packages working, but this is not always straightforward. 
Your friendly LSDTopoTools developers prefer the https://conda.io/miniconda.html[miniconda] environment, so we are going to build a container on top of the https://hub.docker.com/r/conda/miniconda3/[miniconda3 image].

. The dockerfile to start looks like this:
+
[source,dockerfile]
----
FROM conda/miniconda3

COPY . /app
WORKDIR /app
----
+
. Again, we need to build this container in order to use it:
+
[source,console]
----
$ docker build -t chumbucket2 .
----
+
. We can see what images are available with the call
+
[source,console]
----
$ docker images -a
----
+
. You will notice the conda image is 228 MB vs the 78.7 MB: the conda version has more bells and whistles involved in getting miniconda to work.
But the end result is that you can install things using conda. Let's update the image with a conda install. Here is the dockerfile:
+
[source,dockerfile]
----
# Use the miniconda distribution. 
FROM conda/miniconda3

# Add the app directory and set app to the working directory
COPY . /app
WORKDIR /app

# Now add some conda packages
RUN conda install -y numpy
----
+
. And we can build this once more (with the same build call so we don't create a totally new container):
+
[source,console]
----
$ docker build -t chumbucket2 .
----
+
. Now we can open this container in the interactive mode:
+
[source,console]
----
$ docker run -it chumbucket2 sh
----
+
. If you run python inside this container and then `import numpy as np` you can see that it has been installed. 
. From here you should be able to see that we can install all sorts of stuff from the dockerfile using the `RUN conda install` command. 
+
.Some Gotchas in simple containers
**********************************
So far it seems like smooth sailing?
Well there are a few gotchas. 

Firstly, in the command `docker run -it chumbucket2 sh` you can see we are using `sh`: this is in most of the "getting started" docker documentation. 
However, using `sh` really sucks since it does not feature any of the Linux command line shortcuts you are used to. Instead, you should us `bash`.

Secondly even through you have copied the ./app directory into the container, it does not communicate with your storage.
So if you update anything in that directory on your home computer, you need to completely rebuild the container!
**********************************

===== Mounting volumes in Docker

. What we really want is exchange of files between your host operating system and your docker container. 
. You might start by reading about https://docs.docker.com/storage/volumes/[docker volumes]. But like most Docker documenattion that is a bit impenetrable so you might move on to some plain english summaries: https://rominirani.com/docker-tutorial-series-part-7-data-volumes-93073a1b5b72[summary 1] and https://rominirani.com/docker-on-windows-mounting-host-directories-d96f3f056a2c[summary 2]. 
. The upshot of this is that you don't really want a docker volume container, but rather you want to link your docker container to your host file system. 
. On MacOS and Linux this works automatically, but on Windows 10 you need to activate it. Right click on the docker icon in the system tray, go to *Settings* and then to *Shared Drives* and activate drive sharing. 
. Once you have done this you can activate the drive sharing with the `-v` flag in a docker run command (see below). 

===== An LSDMappingTools container

. Okay, lets make a container for https://github.com/LSDtopotools/LSDMappingTools[LSDMappingTools]. 

. The dockerfile looks like this:
+
[source,dockerfile]
----
# This is the LSDMappingTools dockerfile. It is currently set up to install the 
# latest versions of the various required python packages

# To run this you will need to connect it to your host directories if you want to be able to retrieve
# your figures and get data in and out of the container. 
# On windows you need to allow docker access to the host drive
# Right click on the docker icon in your system tray
# Then select "settings"
# Then "Shared Drives" and activate the drive you want
# In MacOS and Linux this is automatically set up. 
# After you build the container
# e.g.
# docker build -t lsdmt .
# 
# Then you need to run it with the volume attached
# e.g.
# docker run C:/Docker_containers/python_containers/LSDMappingTools:/LSDTopoTools/LSDMappingTools lsdmt bash

# Use the miniconda distribution. 
FROM conda/miniconda3

LABEL MAINTAINERS = "Simon Marius Mudd <simon.m.mudd@ed.ac.uk>, Fiona J Clubb <clubb@uni-potsdam.de>"

# Set LSDTopoTools to be the working directory
# This will create a directory in the root of the container. 
# When you start the container you will be placed in this directory. 
WORKDIR /LSDTopoTools

# Now add some conda packages
RUN conda config --add channels conda-forge
RUN conda install -y numpy matplotlib pandas scipy
RUN conda install -y gdal shapely fiona rasterio pyproj
RUN conda install -c conda-forge descartes
----
+
WARNING: This takes a very long time to set up! 
+
. This doesn't include the actual python scripts! 
You need to copy them into a directory where docker can access them (on my machine this means withing the C: drive) and then add them using a volume command:
+
. First build the container:
+
[source,console]
----
$ docker build -t lsdmt .
----
+
. Then run the container in interactive mode with the volume attached:
+
[source,console]
----
$ docker run -it -v C:/Docker_containers/python_containers/python_test1/LSDMappingTools:/LSDTopoTools/LSDMappingTools lsdmt bash
----
+
. Note that this container has *many* python packages so it is rather larege: nearly 4GB (to see, type `docker ps -as`).

===== An LSD Documentation container

. We use https://asciidoctor.org/[asciidoctor] for our documentation. 
I am pleased to say that there is a dockerfile for asciidoctor. 

. Simply copy the https://github.com/asciidoctor/docker-asciidoctor[asciidoctor dockerfile] and add two lines:
+
[source,dockerfile]
----
    awesome_print \
    bundler \
----
+
these come after the line `tile \` on line 55.
+
. Now build the container
+
[source,console]
----
$ docker built -t asc .
----
+
. Then open that container up linking to the proper directory. I use:
+
[source,console]
----
$ docker run -it -v C:/Docker_containers/ruby_containers/LSDTT_documentation/master:/documents/LSDTT_documents asc bash
----
+
. You can find this dockerfile within the https://github.com/LSDtopotools/LSDTT_documentation/blob/master/dockerfile[LSDTT Documentation repository].
+
. When that is running, go into the documentation directory and run our python script:
+
[source,console]
----
# cd LSDTT_documentation
# python compile_LSDTTDocs.py
----
+
. The resulting website will be in the directory `html_build`. 

===== The LSDTT core code container

. We actually have two containers for this since a subset of our code uses PCL which is massive. 
. The simpler version, used in most of our code, is the following:
+
[source,dockerfile]
----
# Pull base image.
FROM ubuntu:18.10

RUN apt-get update
RUN apt-get install -y build-essential git gdal-bin python-gdal libfftw3-dev cmake

WORKDIR /LSDTopoTools

----
+
. We can also use an Alpine linux version, which is *much* smaller:
+
[source,dockerfile]
----
FROM alpine
MAINTAINER Simon Mudd (simon.m.mudd@ed.ac.uk) and Fiona Clubb (clubb@uni-potsdam.de)

# install essential packages
RUN apk upgrade -U && \
    apk update && \
    apk add --virtual build-dependencies build-base gcc wget git && \
    apk add --repository http://dl-cdn.alpinelinux.org/alpine/edge/main libressl2.7-libcrypto && \
    apk add gdal --update-cache --repository http://dl-cdn.alpinelinux.org/alpine/edge/testing && \
    apk add fftw-dev cmake && \
    rm -rf /var/cache/apk/* && \
    rm -rf /tmp/*

# update to avoid weird apk error 
RUN apk update

# clone LSDTT repo
WORKDIR /home/

RUN git clone https://github.com/LSDtopotools/LSDTT_public.git
----



===== The LSDTT PCL container

Some of our routines need the [Point Cloud Library]. This is a *HUGE* library that needs millions of additional bits of software.
The resulting container is enormous, and takes an age to build so you should only use this if you need the PCL versions of *LSDTopoTools*.

One quite annoying thing is that for anything later than Ubuntu 14 you need to build PCL from source. This takes a *long* time. 
The whole installation process takes an age. Sorry. 

This is the dockerfile:

[source,docker]
----
# Pull base image.
FROM ubuntu:16.04

# These are the basic build tools
RUN apt-get update
RUN apt-get install -y build-essential git gdal-bin python-gdal libfftw3-dev cmake

# And this is the point cloud library

# install pcl
RUN apt-get install -y libpcl-dev

# We need this as well
RUN apt-get install -y libproj-dev
    
WORKDIR /LSDTopoTools
----

