:numbered:

By now you should have the *chi mapping tool* compiled and ready to run. 

The next step is to create a parameter file to tell the code how to analyse your data. 

== The parameters

.Quick guide if you already know what you are doing
*****************************************************************************

Here is a quick overview of how to set up and run the code, if you have run a *LSDTopoTools* analysis before:

. The beginning of your parameter file has information about the location and names of the input/ouput:

[source,paramfile]
----
read path: /home/boris/path/to/file/
read fname: name_of_dem_without_extension

write path: /home/boris/path/to/file/
write fname: prefix_for_output
----

. These parameters are linked to drainage network extraction, an exhaustive list is provided later. Here is a basic drainage extraction:
[source,paramfile]
----
threshold_contributing_pixels: 2000
minimum_basin_size_pixels: 200000
maximum_basin_size_pixels: 5000000
m_over_n: 0.45
----
. The following parameters are defining the $k_{sn}$ extraction, using Mudd et al., 2014 JGR algorithm:
.. `force_skip_knickpoint_analysis: 2`: Number of nodes skipped during each montecarlo iterations. 1 - 4. A lower value means a better fit to chi-plot profile, but also more sensitive to noise.
.. `force_n_iteration_knickpoint_analysis: 40`: number of iteration for the segment testing. 20 is the minimum, over that value it does not change a lot the calculation.
.. `target_nodes: 80`: Will set the number of nodes investigated per segment. combined with `force_skip_knickpoint_analysis`, it will determine the size of the segments and thus the precision of the fitting (do you want the main trend or detail analysis?). *Over 100 nodes, it becomes computationally really expensive, over 120, you will need days of processing, over 150, probably months, over 200 you won't be alive when the results will strike. It depends on your priorities.* 50-100 nodes will fit most of the needs.
.. Other less affecting parameters can be adjusted for the segment fitting algorithm, you can refer to the documentation from Mudd et al., 2014 JGR.

. The following parameter are controlling the knickpoint extraction:
.. `ksn_knickpoint_analysis: true`: switch on the analysis, as other analysis are available through `chi_mapping_tools.exe`, namely Chi extraction, $M_\chi$ extraction from Mudd et al., 2014 JGR and concavity index extraction from Mudd et al., 2018 Esurf.
.. `TVD_lambda: -1`: define the regulation parameter for the Total Variation Denoising algorithm, adapted from Condat, 2013. `-1` will choose an automatic value depending on your m/n. This parameter depends on the magnitude of $k_{sn}$ and can be adjusted manually. Higher $\lambda$ will produce a clearer signal but may inhibit or lower some knickpoint ($\Delta k_{sn}$).
.. `kp_node_combining: 10`: Determine the combining window for $\Delta k_{sn}$ knickpoint. It avoids getting artifact knickpoints, but a high window can shift knickpoint location. A low window can scatter large knickpoints into successive small ones.
.. `window_stepped_kp_detection: 100`: Determine the window for windowed statistics on segmented elevation to detect stepped knickpoints. Low windows are unefficient to catch these steps.
.. `std_dev_coeff_stepped_kp: 8`: Std deviation threshold to catch these variations. 7 - 9 gives a pretty reliable results. Lower value would produce many artifacts.
*****************************************************************************
